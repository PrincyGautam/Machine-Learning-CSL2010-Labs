# -*- coding: utf-8 -*-
"""Lab 4_Part2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KQCWvDOv1j4I0v8W9HfrTRi8cw7RacTu
"""

import numpy as np
import pandas as pd
import math
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier
from scipy.stats import mode
from sklearn.metrics import confusion_matrix 
df = pd.read_csv("/content/diabetes (1) (1).csv")
df.head()

X =  df.iloc[:,:-1].values
Y =  df.iloc[:,-1:].values

from sklearn.model_selection import train_test_split
train_ratio = 0.70
validation_ratio = 0.15
test_ratio = 0.15

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=1 - train_ratio)
X_val, X_test, Y_val, Y_test = train_test_split(X_test, Y_test, test_size=test_ratio/(test_ratio + validation_ratio)) 

print("Train:", X_train.shape[0])
print("Val:", X_val.shape[0])
print("Test:", X_test.shape[0])

from scipy.stats import mode
from sklearn.metrics import confusion_matrix 
class KNN():
    def __init__(self, k ) :  
        self.k = k
          
    def fit(self, X_train, Y_train ) :  
        self.X_train = X_train  
        self.Y_train = Y_train  
        self.m, self.n = X_train.shape

    def euclidean(self, x, x_train ) :
        return np.sqrt(np.sum((x - x_train )**2 ))

    def predict(self, X_test ) :
        self.X_test = X_test
        self.m_test, self.n = X_test.shape
        Y_predict = np.zeros(self.m_test )
        for i in range(self.m_test ) :
            x = self.X_test[i]
            neighbors = np.zeros(self.k )
            neighbors = self.nearest_nbrs(x)
            Y_predict[i] = mode(neighbors)[0][0]    
        return Y_predict
        
    

    def nearest_nbrs(self, x) :
        ed = np.zeros(self.m )  
        for i in range(self.m) :
            d = self.euclidean(x, self.X_train[i])
            ed[i] = d
        sorted_list = ed.argsort()
        Y_train_sorted = self.Y_train[sorted_list]
        return Y_train_sorted[:self.k]

def main():
    def accuracy_metric(Y_test, Y_pred):
        correct = 0
        for i in range(len(Y_test)):
            if Y_test[i] == Y_pred[i]:
                correct += 1
        return correct / float(len(Y_test)) * 100.0
    for k in k_list:
        model = KNN(k)
        model.fit(X_train,Y_train)
        Y_predict=model.predict(X_test)
        accu = accuracy_metric(Y_test, Y_predict)
        cnf_mat= confusion_matrix(Y_test, Y_predict)
        print("The accuracy of our classifier with k = ",k,"is {}".format(accu))
        print("Confusion matrix of our classifier with k = ",k,"is {}".format(cnf_mat))
if __name__=="__main__":
    main()

#cross validation
#THERE'S ONE ERROR IN THIS PART BUT DESPITE THAT IT GIVES THE CORRECT OUTPUT(i.e., OPTIMAL VALUE OF k)
from sklearn.model_selection import cross_val_score
k_list = list(range(5,10))
cv_scores = []
for k in k_list:
    knn = KNeighborsClassifier(k)
    scores = cross_val_score(knn, X_train, Y_train, cv=10, scoring = 'accuracy')
    cv_scores.append(scores.mean())
error = [1 - x for x in cv_scores]

optimal_k = k_list[error.index(min(error))]
print("The optimal number of neighbors is {}".format(optimal_k))
plt.plot(k_list, error)
plt.xlabel("K")
plt.ylabel("Error Rate")
plt.show()

error_rate = [] 
for i in range(5,10):
    knn = KNN(i)
    knn.fit(X_train,Y_train)
    pred_i = knn.predict(X_test)
    error_rate.append(np.mean(Y_test != pred_i))
    
    
plt.plot(range(5,10),error_rate, color = 'black', linestyle = 'dashed', marker = 'o', markerfacecolor = 'red', markersize = 8)
plt.title("Error Rate v/s K")
plt.xlabel("K")
plt.ylabel("Error Rate")
print("Minimum error:",min(error_rate),"at k = 8")

from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics
from sklearn.metrics import confusion_matrix 
knn = KNeighborsClassifier(n_neighbors=8, metric ='euclidean')
knn.fit(X_train,Y_train)
Y_pred = knn.predict(X_test)
Y_pred
cnf_matrix= confusion_matrix(Y_test, Y_pred)  
print("Accuracy of Sklearn model: ",100*metrics.accuracy_score(Y_test,Y_pred))
print("Confusion matix of Sklearn mode:",cnf_matrix)

print('\n')

def accuracy_metric(Y_test, Y_pred):
    correct = 0
    for i in range(len(Y_test)):
        if Y_test[i] == Y_pred[i]:
            correct += 1
    return correct / float(len(Y_test)) * 100.0
model = KNN(8)
model.fit(X_train,Y_train)
Y_predict=model.predict(X_test)
accu = accuracy_metric(Y_test, Y_predict)
cnf_mat= confusion_matrix(Y_test, Y_predict)

print("The accuracy of our classifier with optimal k = 8 is {}".format(accu))
print("Confusion matrix of our classifier with optimal k = 8 is {}".format(cnf_mat))