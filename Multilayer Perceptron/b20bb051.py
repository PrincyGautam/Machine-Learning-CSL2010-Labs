# -*- coding: utf-8 -*-
"""B20BB051.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ritteoj-9GjtbswwNJNuLF52YGCP7YH8
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from sklearn import preprocessing
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, mean_squared_error

iris_data = pd.read_csv('/content/Iris (1).csv')
iris_data.head()

features = iris_data.iloc[:,[1,2,3,4]]
target = iris_data.iloc[:,5]

sc = StandardScaler()
x = sc.fit_transform(features)

enc = preprocessing.LabelEncoder()
y = enc.fit_transform(np.array(target))

x_train, x_test , y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=11)

mlp = MLPClassifier(hidden_layer_sizes=(60,50), max_iter=50, learning_rate='constant',learning_rate_init=0.05, random_state=0)
mlp.fit(x_train, y_train)
y_predict1 = mlp.predict(x_test )
print("Score of model : ",mlp.score(x_train, y_train))
accurcy1 = accuracy_score(y_test, y_predict1)
print("Accuracy of Model is :",accurcy1,"\n")

mlp = MLPClassifier(hidden_layer_sizes=(60,50), max_iter=50, learning_rate='adaptive', learning_rate_init=0.01, random_state=0)
mlp.fit(x_train, y_train)
y_predict2 = mlp.predict(x_test )
print("Score of model : ",mlp.score(x_train, y_train))
accurcy2 = accuracy_score(y_test, y_predict2)
print("Accuracy of Model is :",accurcy2,"\n")

mlp = MLPClassifier(hidden_layer_sizes=(60,50), max_iter=50, learning_rate='invscaling', learning_rate_init=0.005, random_state=0)
mlp.fit(x_train, y_train)
y_predict3 = mlp.predict(x_test )
print("Score of model : ",mlp.score(x_train, y_train))
accurcy3 = accuracy_score(y_test, y_predict3)
print("Accuracy of Model is :",accurcy3,"\n")

loss = []
for max_iter in range(10, 110, 10):
    mlp = MLPClassifier(hidden_layer_sizes=(60,50), activation='relu', learning_rate_init=0.05, learning_rate='constant', max_iter=max_iter, random_state=10)
    mlp.fit(x_train, y_train)
    y_predict = mlp.predict(x_test )
    mse = mean_squared_error(y_test, y_predict)
    loss.append(mse)

Max_iter = [x for x in range(10, 110, 10)]
plt.plot(Max_iter, loss, color="green")
plt.xlabel("Epochs", fontsize=15)
plt.ylabel("Loss", fontsize=15)
plt.title("Model loss", fontsize=20)
plt.show()

########################################################################################################################################

from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectFromModel
test = pd.read_csv("/content/test.csv")


nanCounts = test.isna().sum()
nanTotal = test.isna().sum().sum()
print('NaN\'s found: ', nanTotal)

nanCols = []
for i in range(0,len(nanCounts)):
    if nanCounts[i] > 0:
        nanCols.append(test.columns[i])

for i in nanCols:
    if test[nanCols][i].dtypes == 'float64':
        test[i] = test[i].fillna(test[i].mean())
    elif test[nanCols][i].dtypes == 'object':
        test[i] = test[i].fillna('XX')

nanTotal = test.isna().sum().sum()

print('NaN\'s after removal: ', nanTotal)

categorical = []
for i in range(0, len(test.dtypes)):
    if test.dtypes[i] == 'object':
        categorical.append(test.columns[i])

print('Categorical columns are: \n', categorical)

OHE_sdf = pd.get_dummies(test[categorical])

test.drop(columns = categorical, axis = 1, inplace = True)

test = pd.concat([test, OHE_sdf], axis = 1, ignore_index = False)

train = pd.read_csv("/content/train.csv")


nanCounts = train.isna().sum()
nanTotal = train.isna().sum().sum()
print('NaN\'s found: ', nanTotal)

nanCols = []
for i in range(0,len(nanCounts)):
    if nanCounts[i] > 0:
        nanCols.append(train.columns[i])

for i in nanCols:
    if train[nanCols][i].dtypes == 'float64':
        train[i] = train[i].fillna(train[i].mean())
    elif train[nanCols][i].dtypes == 'object':
        train[i] = train[i].fillna('XX')

nanTotal = train.isna().sum().sum()

print('NaN\'s after removal: ', nanTotal)

categorical = []
for i in range(0, len(train.dtypes)):
    if train.dtypes[i] == 'object':
        categorical.append(train.columns[i])

print('Categorical columns are: \n', categorical)

OHE_sdf = pd.get_dummies(train[categorical])

train.drop(columns = categorical, axis = 1, inplace = True)

train = pd.concat([train, OHE_sdf], axis = 1, ignore_index = False)

print('splitting dataset...')
x_train, x_test, y_train, y_test = train_test_split(train, train['SalePrice'], test_size = 0.3, random_state = 42)

print('Selecting features')
sel = SelectFromModel(RandomForestClassifier(n_estimators = 100), threshold = '1.25*mean')
sel.fit(x_train, y_train)
selected = sel.get_support()

print(selected)
print(train.columns[selected])

train.head()

test.head()

from sklearn import linear_model
X = train.drop(columns=['SalePrice'])
y = train["SalePrice"]

lp = MLPClassifier(hidden_layer_sizes=1, activation='relu')
model = lp.fit(X,y)

predictions = lp.predict(X)
print('Predictions: \n',predictions[0:5])

from sklearn.neural_network import MLPRegressor
Y_test = pd.read_csv('/content/sample_submission.csv')

Y_test.drop(['Id'], axis=1, inplace=True)

"""### Train data"""

train.isna().any()

tr = train.dropna(axis=1)

tr.drop(['Id'], axis=1, inplace=True)


tr.info()

categories = tr.select_dtypes(include=['object'])

x_train = pd.get_dummies(tr, columns=categories.columns)



scaler = StandardScaler()

scaler.fit(x_train)

x_train = scaler.transform(x_train)

scaler.fit(x_test)

x_test = scaler.transform(x_test)
mlr = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, activation='relu', solver='sgd', early_stopping=True)

mlr.fit(x_train, y_train)

res_train = mlr.predict(x_train)

mlr.score(x_train, y_train)

res_train[:5]

res_test = mlr.predict(x_test)

mlr.score(x_test, res_test)

res_test[:5]

### Average mean squared error"""

mse = mean_squared_error(Y_test, predicted)

avg_mse = mse/len(predicted)

avg_mse

## Euclidean and Manhattan Distances

Y_test = Y_test.to_numpy()

l1 = manhattan_distances(Y_test.reshape(1, -1), predicted.reshape(1, -1))

l2 = euclidean_distances(Y_test.reshape(1, -1), predicted.reshape(1, -1))

l1[0][0]

l2[0][0]

pd.DataFrame(regressor.loss_curve_).plot();

plt.hist(reg.loss_curve_, bins=3);